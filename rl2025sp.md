---
title: "Reinforcement Learning (Spring 2025)"
permalink: "/rl2025sp/"
layout: page-course
show_navigation: false
---

<br/><br>

## Course Information
- **Time**: Monday & Wednesday 9:30-10:45AM  
- **Location**: Rice 340   
- **Instructor and office hours**: [Chen-Yu Wei](https://bahh723.github.io/), Tuesday 3-4PM @ Rice 409     
- **TA and office hours**: [Braham Snyder](https://www.braham.io/){:target="_blank"}, Friday 4-5PM @ Rice 442   


## Overview  
Reinforcement learning (RL) is a powerful learning paradigm through which machines learn to make (sequential) decisions. It has been playing a pivotal role in advancing artificial intelligence, with notable successes including <a href="https://www.nature.com/articles/nature16961" target="_blank">mastering the game of Go</a> and <a href="https://openai.com/index/instruction-following/" target="_blank">enhancing large language models</a>.  

This course focuses on the design principles of RL algorithms. Similar to statistical learning, a central challenge in RL is to **generalize** learned capabilities to unseen environments.  However, RL also faces additional challenges such as **exploration-exploitation tradeoff**, **credit assignment**, and **distribution mismatch** between behavior and target policies. Throughout the course, we will delve into various solutions to these challenges and provide theoretical justifications.  

## Prerequisites  
This course is mathematically demanding. Students are expected to have strong foundations in **probability**, **linear algebra**, and **calculus**. A basic understanding of machine learning and convex optimization will be beneficial. Proficiency in **python** programming is required. 

## Topics 
Bandits, online learning, dynamic programming, Q-learning, policy evaluation, policy gradient. 

## Platforms
- [Piazza](https://piazza.com/class/m5v3ed2f1f63ei/){:target="_blank"}: Discussions  
- [Gradescope](https://www.gradescope.com/courses/968387){:target="_blank"}: Homework submissions  


## Grading
- (70%) **Assignments**        
- (30%) **Final project**   

**Late policy for assignments**: 10 free late days can be used across all assignments. Each additional late day will result in a 10% deduction in the semester's assignment grade.  No assignment can be submitted more than 7 days after its deadline.  



## Schedule

One slide deck may be used for multiple lectures. 

| Date    | Topics    |  Materials   |  Assignments  |
|:----------------|:----------------|:----------------|:----------------|
| 1/13 | **Introduction** | [Slides](/rl2025sp_files/introduction.pdf){:target="_blank"}, [Recording](https://virginia.zoom.us/rec/share/LOizdQbexpbBT8RsRuRujEIjsJPN2C7Vkxrnt7rv_w-7nBf9sPFuWj-4sTWGr-qD.Usoe7v8ynvlY6Ddi){:target="_blank"} | [HW0](/rl2025sp_files/HW0.pdf){:target="_blank"} (no submission needed) |
| 1/15 | **Value-based bandits**: Explore-then-exploit, &epsilon;-greedy | [Slides](/rl2025sp_files/bandits1.pdf){:target="_blank"}, [Recording](https://virginia.zoom.us/rec/share/6r_YblVPYKHMTHvusfD9ybQJuCtAfX2tcCqkVqBJ5GEyN9DNZEcrnVgI_wU-QYWY.WL2zs2sFlOWpUf_e){:target="_blank"} |  |
| 1/20 | <span style="color:lightgray">MLK Holiday</span>  |  |  | 
| 1/22 | Boltzmann exploration, Inverse gap weighting, Reduction | [Recording](https://virginia.zoom.us/rec/share/mpNKMAsgr_RpvKJi5jE2fpHc2rjvx35LLGJNPQzMZboSOJlSmqz3hpd_TaL23k9T.0Ly0ut2A7fyfiJy6){:target="_blank"}, [Supp-IGW](/rl2025sp_files/igw.pdf){:target="_blank"} |  |
| 1/27 | UCB, TS | [Recording](https://virginia.zoom.us/rec/share/kItwByOYyq2i8dfIY4mzoTn5WD2vTfe1oTKHTdDhJLwTwrdzB1o43aJDKSntZ7rD.2z_XuQDLVSzO5h7G){:target="_blank"} | [HW1](/rl2025sp_files/HW1.pdf) out |
| 1/29 | **Policy-based bandits**: Exponential weights (full-information) | [Slides](/rl2025sp_files/bandits2.pdf){:target="_blank"}, [Recording](https://virginia.zoom.us/rec/share/5uLjWL23bqaYIFa1Q021cOVE93TsigiNH4HZjvIDrtTnOP4X-rQb3awH-bV5P1Mz.Z9D0IZ2eLmylsFgf){:target="_blank"} |  |
| 2/3 | EXP3 | [Recording](https://virginia.zoom.us/rec/share/6qOFhOvmILUKuwgY8aJ5yJwnHQgOuIGpck2-rjU0GhUm5uvwnmNlo0wj6SZOstok.AX0hnpi_MW1jq3iY){:target="_blank"} |  |
| 2/5 | PPO | [Recording](https://virginia.zoom.us/rec/share/FH6LEG6OIoivCApAEQdsdxHKz15aDbPa_D6s36qVLzm5KyZcUWMOklnfY9Qd0UNz.EQDGKgyDlteWx0Up){:target="_blank"} | HW1 due on 2/7 |
| 2/10 | NPG, PG | [Recording](https://virginia.zoom.us/rec/share/5LJDB6Sy0HzItbHYx8-71gUFSIC0Kj7lcu8cHua2PZUl9CpSVEc00EMUMpKus8JB.278SAGuQjr88hVVp){:target="_blank"} |  |
| 2/12 |  |  | [HW2](/rl2025sp_files/HW2.pdf){:target="_blank"} out |
| 2/17 |  |  |  |
| 2/19 |  |  |  |
| 2/24 |  |  |  |
| 2/26 |  |  | HW2 due on 2/26 |
| 3/3 |  |  |  |
| 3/5 |  |  |  |
| 3/10 | <span style="color:lightgray">Spring recess</span>  |  |  |
| 3/12 | <span style="color:lightgray">Spring recess</span> |  |  |
| 3/17 |  |  |  |
| 3/19 |  |  |  |
| 3/24 |  |  |  |
| 3/26 |  |  |  |
| 3/31 |  |  |  |
| 4/2 |  |  |  |
| 4/7 |  |  |  |
| 4/9 |  |  |  |
| 4/14 |  |  |  |
| 4/16 |  |  |  |
| 4/21 |  |  |  |
| 4/23 |  |  |  |
| 4/28 |  |  |  |

## Resources
- [Bandit Algorithms](https://tor-lattimore.com/downloads/book/book.pdf){:target="_blank"} by Tor Lattimore and Csaba Szepesvari   
- [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html){:target="_blank"} by Richard Sutton and Andrew Barto  
- [Reinforcement Learning: Theory and Algorithms](https://rltheorybook.github.io/){:target="_blank"} by Alekh Agarwal, Nan Jiang, Sham Kakade, and Wen Sun  
- [Statistical Reinforcement Learning and Decision Making: Course Notes](https://www.mit.edu/~rakhlin/courses/course_stat_rl/course_stat_rl.pdf){:target="_blank"} by Dylan Foster and Sasha Rakhlin


## Previous Offerings    
- [CS 6501 Reinforcement Learning (Spring 2024)](https://bahh723.github.io/rl2024sp/){:target="_blank"}
- [CS 6501 Topics in Reinforcement Learning (Fall 2022)](https://shangtongzhang.github.io/teaching/cs6501_fall_22/index){:target="_blank"} by Prof. Shangtong Zhang  




