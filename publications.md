---
title: "Publications"
permalink: "/publications/"
layout: page
---

## Preprints

- **Tractable Local Equilibria in Non-Concave Games**  
(&alpha;-&beta;) Yang Cai, Constantinos Daskalakis, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng  
[[arXiv](https://arxiv.org/abs/2403.08171){:target="_blank"}]  


- **Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data**  
(&alpha;-&beta;) Zeyu Jia, Alexander Rakhlin, Ayush Sekhari, Chen-Yu Wei   
[[preprint](https://bahh723.github.io/document/offline-rl.pdf){:target="_blank"}]  

## Publications 

### 2024 

- **Near-Optimal Policy Optimization for Correlated Equilibrium in General-Sum Markov Games**  
(&alpha;-&beta;) Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng  
*AISTAT 2024* <span style="color:red">(Oral)</span> 
[[arXiv](https://arxiv.org/abs/2401.15240){:target="_blank"}]  


- **Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback**  
(&alpha;-&beta;) Haolin Liu, Chen-Yu Wei, Julian Zimmert  
*ICLR 2024* <span style="color:red">(Spotlight)</span> 
[[arXiv](https://arxiv.org/abs/2310.11550){:target="_blank"}]  


### 2023


- **Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits**  
(&alpha;-&beta;) Haolin Liu, Chen-Yu Wei, Julian Zimmert  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/abs/2309.00814){:target="_blank"}]  


- **Last-Iterate Convergent Policy Gradient Primal-Dual Methods for Constrained MDPs**  
Dongsheng Ding\*, Chen-Yu Wei\*, Kaiqing Zhang\*, Alejandro Ribeiro  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/abs/2306.11700){:target="_blank"}]  


- **No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions**  
Tiancheng Jin\*, Junyan Liu\*, Chloe Rouyer, William Chang, Chen-Yu Wei, Haipeng Luo  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/abs/2305.17380){:target="_blank"}]


- **First- and Second-Order Bounds for Adversarial Linear Contextual Bandits**  
Julia Olkhovskaya, Jack Mayo, Tim van Erven, Gergely Neu, Chen-Yu Wei  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/abs/2305.00832){:target="_blank"}]


- **Uncoupled and Convergent Learning in Two-Player Zero-Sum Markov Games**  
(&alpha;-&beta;) Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/abs/2303.02738){:target="_blank"}]


- **A Blackbox Approach to Best of Both Worlds in Bandits and Beyond**  
(&alpha;-&beta;) Christoph Dann, Chen-Yu Wei, Julian Zimmert  
*COLT 2023* 
[[arXiv](https://arxiv.org/abs/2302.09739){:target="_blank"}] [[slides](https://bahh723.github.io/document/blackbox-approach-to-best-of-both-worlds.pdf){:target="_blank"}]



- **Best of Both Worlds Policy Optimization**  
(&alpha;-&beta;) Christoph Dann, Chen-Yu Wei, Julian Zimmert  
*ICML 2023* <span style="color:red">(Long Talk)</span> 
[[arXiv](https://arxiv.org/abs/2302.09408){:target="_blank"}] [[slides](https://bahh723.github.io/document/best-of-both-worlds-policy-optimization.pdf){:target="_blank"}]



- **Refined Regret for Adversarial MDPs with Linear Function Approximation**  
(&alpha;-&beta;) Yan Dai, Haipeng Luo, Chen-Yu Wei, Julian Zimmert  
*ICML 2023* 
[[arXiv](https://arxiv.org/abs/2301.12942){:target="_blank"}] [[slides](https://diamond-duke.github.io/files/slides_ICML2023_Linear_AMDP.pdf){:target="_blank"}]



- **A Unified Algorithm for Stochastic Path Problems**  
(&alpha;-&beta;) Christoph Dann, Chen-Yu Wei, Julian Zimmert  
*ALT 2023* 
[[arXiv](https://arxiv.org/abs/2210.09255){:target="_blank"}] [[slides](https://bahh723.github.io/document/unified-stochastic-path.pdf){:target="_blank"}]



### 2022

- **Independent Policy Gradient for Large-Scale Markov Potential Games: Sharper Rates, Function Approximation, and Game-Agnostic Convergence**  
Dongsheng Ding\*, Chen-Yu Wei\*, Kaiqing Zhang\*, Mihailo Jovanovic  
*ICML 2022* <span style="color:red">(Long Talk)</span> 
[[arXiv](https://arxiv.org/abs/2202.04129){:target="_blank"}] [[video](https://slideslive.com/38983099/independent-policy-gradient-for-largescale-markov-potential-games-sharper-rates-function-approximation-and-gameagnostic-convergence){:target="_blank"}]



- **Personalization Improves Privacy-Accuracy Tradeoffs in Federated Optimization**  
Alberto Bietti, Chen-Yu Wei, Miroslav Dudik, John Langford, Zhiwei Steven Wu  
*ICML 2022* 
[[arXiv](https://arxiv.org/abs/2202.05318){:target="_blank"}] [[video](https://slideslive.com/38983416/personalization-improves-privacyaccuracy-tradeoffs-in-federated-learning){:target="_blank"}]



- **Decentralized Cooperative Reinforcement Learning with Hierarchical Information Structure**  
Hsu Kao, Chen-Yu Wei, Vijay Subramanian  
*ALT 2022* 
[[arXiv](https://arxiv.org/abs/2111.00781){:target="_blank"}] 
[[slides](https://bahh723.github.io/document/decentralized-cooperative-rl-in-hierarchical-mdp.pdf){:target="_blank"}]


- **A Model Selection Approach for Corruption Robust Reinforcement Learning**  
Chen-Yu Wei, Christoph Dann, Julian Zimmert  
*ALT 2022*  <span style="color:red">(Best Paper Award)</span> 
[[arXiv](https://arxiv.org/abs/2110.03580){:target="_blank"}] [[slides](https://bahh723.github.io/document/model-selection-for-corrupted-mdp.pdf){:target="_blank"}]


### 2021

- **Policy Optimization in Adversarial MDPs:  Improved Exploration via Dilated Bonuses**  
Haipeng Luo\*, Chen-Yu Wei\*, Chung-Wei Lee  
*NeurIPS 2021* 
[[arXiv](https://arxiv.org/abs/2107.08346){:target="_blank"}] 
[[slides](https://bahh723.github.io/document/policy-optimization-in-adversarial-mdp-with-dilated-bonus.pdf){:target="_blank"}]
[[slides](https://bahh723.github.io/document/exploration-bonus-for-policy-optimization.pdf){:target="_blank"}] [[video](https://slideslive.com/38968587/policy-optimization-in-adversarial-mdps-improved-exploration-via-dilated-bonuses){:target="_blank"}]


- **Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic and Adversarial Linear Bandits Simultaneously**  
(&alpha;-&beta;) Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang, Xiaojin Zhang  
*ICML 2021* 
[[arXiv](https://arxiv.org/abs/2102.05858){:target="_blank"}] [[slides](https://bahh723.github.io/document/best-of-both-worlds-for-linear-bandits.pdf){:target="_blank"}] [[video](https://slideslive.com/38959312/achieving-near-instanceoptimality-and-minimaxoptimality-in-stochastic-and-adversarial-linear-bandits-simultaneously){:target="_blank"}]


- **Non-stationary Reinforcement Learning without Prior Knowledge: An Optimal Black-Box Approach**  
Chen-Yu Wei and Haipeng Luo  
*COLT 2021*  <span style="color:red">(Best Paper Award)</span> 
[[arXiv](https://arxiv.org/abs/2102.05406){:target="_blank"}] [[slides](https://bahh723.github.io/document/non-stationary-rl.pdf){:target="_blank"}] [[slides](https://bahh723.github.io/document/non-stationary-bandit.pdf){:target="_blank"}] [[video](https://www.youtube.com/watch?v=kLMVbPnD5kc){:target="_blank"}]


- **Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent in Infinite-Horizon Competitive Markov Games**  
Chen-Yu Wei, Chung-Wei Lee\*, Mengxiao Zhang\*, Haipeng Luo  
*COLT 2021* 
[[arXiv](https://arxiv.org/abs/2102.04540){:target="_blank"}] [[slides](https://bahh723.github.io/document/last-iterate-convergence-of-ogda-in-markov-games.pdf){:target="_blank"}]

- **Impossible Tuning Made Possible: A New Expert Algorithm and Its Applications**  
(&alpha;-&beta;) Liyu Chen, Haipeng Luo, Chen-Yu Wei  
*COLT 2021* 
[[arXiv](https://arxiv.org/abs/2102.01046){:target="_blank"}] [[slides](https://bahh723.github.io/document/impossible-tuning-made-possible.pdf){:target="_blank"}]

- **Minimax Regret for Stochastic Shortest Path with Adversarial Costs and Known Transition**  
Liyu Chen, Haipeng Luo, Chen-Yu Wei  
*COLT 2021* 
[[arXiv](https://arxiv.org/abs/2012.04053){:target="_blank"}] [[slides](https://bahh723.github.io/document/adversarial-stochastic-shortest-path-with-known-transition.pdf){:target="_blank"}] [[video](https://www.youtube.com/watch?v=uneHM2mm3z0){:target="_blank"}]


- **Learning Infinite-Horizon Average-Reward MDPs with Linear Function Approximation**  
Chen-Yu Wei, Mehdi Jafarnia-Jahromi, Haipeng Luo, Rahul Jain  
*AISTAT 2021* 
[[arXiv](https://arxiv.org/abs/2007.11849){:target="_blank"}] [[slides](https://bahh723.github.io/document/average-reward-linear-mdp.pdf){:target="_blank"}] [[video](https://www.youtube.com/watch?v=NpG97aEctqE){:target="_blank"}]


- **Linear Last-Iterate Convergence in Constrained Saddle-Point Optimization**  
Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, Haipeng Luo  
*ICLR 2021* 
[[arXiv](https://arxiv.org/abs/2006.09517){:target="_blank"}] [[code](https://github.com/bahh723/OGDA-last-iterate){:target="_blank"}] 
[[slides](https://bahh723.github.io/document/linear-last-iterate-convergence-in-constrained-saddle-point-optimization.pdf){:target="_blank"}] [[video](https://slideslive.com/38954127/linear-lastiterate-convergence-in-constrained-saddlepoint-optimization){:target="_blank"}]


- **Adversarial Online Learning with Changing Action Sets: Efficient Algorithms with Approximate Regret Bounds**  
Ehsan Emamjomeh-Zadeh\*, Chen-Yu Wei\*, Haipeng Luo, David Kempe  
*ALT 2021* 
[[arXiv](https://arxiv.org/abs/2003.03490){:target="_blank"}] [[slides](https://bahh723.github.io/document/adversarial-online-learning-with-changing-action-sets.pdf){:target="_blank"}] [[video](https://slideslive.com/38952813/adversarial-online-learning-with-changing-action-sets-efficient-algorithms-with-approximate-regret-bounds){:target="_blank"}]


### 2020

- **Bias No More: High-Probability Data-Dependent Regret Bounds for Adversarial Bandits and MDPs**  
(&alpha;-&beta;) Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang  
*NeurIPS 2020*  <span style="color:red">(Oral)</span> 
[[arXiv](https://arxiv.org/abs/2006.08040){:target="_blank"}] [[slides](https://bahh723.github.io/document/bias-no-more.pdf){:target="_blank"}] [[video](https://slideslive.com/38938490/bias-no-more-highprobability-datadependent-regret-bounds-for-adversarial-bandits-and-mdps){:target="_blank"}]

- **Federated Residual Learning**  
Chen-Yu Wei, Alekh Agarwal, John Langford  
*NeurIPS Workshop on Scalability, Privacy, and Security in Federated Learning 2020* 
[[arXiv](https://arxiv.org/abs/2003.12880){:target="_blank"}] 


- **Taking a Hint: How to Leverage Loss Predictors in Contextual Bandits?**  
Chen-Yu Wei, Haipeng Luo, Alekh Agarwal  
*COLT 2020* 
[[arXiv](https://arxiv.org/abs/2003.01922){:target="_blank"}] [[slides](https://bahh723.github.io/document/how-to-leverage-loss-predictors-in-contextual-bandits.pdf){:target="_blank"}] [[video](https://slideslive.com/38931095/taking-a-hint-how-to-leverage-loss-predictors-in-contextual-bandits){:target="_blank"}]


- **Model-free Reinforcement Learning in Infinite-Horizon Average-Reward Markov Decision Processes**  
Chen-Yu Wei, Mehdi Jafarnia-Jahromi, Haipeng Luo, Hiteshi Sharma, Rahul Jain  
*ICML 2020* 
[[arXiv](https://arxiv.org/abs/1910.07072){:target="_blank"}] 
[[code](https://github.com/bahh723/model-free-rl-algos){:target="_blank"}] [[slides](https://bahh723.github.io/document/model-free-rl-in-infinite-horizon-average-reward-mdp.pdf){:target="_blank"}] [[video](https://slideslive.com/38928250/modelfree-reinforcement-learning-in-infinitehorizon-averagereward-mdps){:target="_blank"}]



### 2019

- **Analyzing the Variance of Policy Gradient Estimators for the Linear-Quadratic Regulator**  
James Preiss\*, Sebastien Arnold\*, Chen-Yu Wei\*, Marius Kloft  
*NeurIPS Workshop on Optimization Foundations for Reinforcement Learning 2019* [[arXiv](https://arxiv.org/abs/1910.01249){:target="_blank"}]  
*SoCal Machine Learning Symposium 2019* <span style="color:red">(Best Poster Award)</span> 

- **A New Algorithm for Non-Stationary Contextual Bandits: Efficient, Optimal, and Parameter-Free**  
(&alpha;-&beta;) Yifang Chen, Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei  
*COLT 2019* 
[[arXiv](https://arxiv.org/abs/1902.00980){:target="_blank"}] 
[[a joint extended abstract with Auer, Gajane, and Ortner](http://proceedings.mlr.press/v99/auer19b.html){:target="_blank"}] [[slides](https://bahh723.github.io/document/a-new-algorithm-for-non-stationary-contextual-bandits.pdf){:target="_blank"}]

- **Improved Path-Length Regret Bounds for Bandits**  
(&alpha;-&beta;) Sebastien Bubeck, Yuanzhi Li, Haipeng Luo, Chen-Yu Wei  
*COLT 2019* 
[[arXiv](https://arxiv.org/abs/1901.10604){:target="_blank"}] [[slides](https://bahh723.github.io/document/improved-path-length-regret-bounds-for-bandits.pdf){:target="_blank"}]


- **Beating Stochastic and Adversarial Semi-Bandits Optimally and Simultaneously**  
Julian Zimmert, Haipeng Luo, Chen-Yu Wei  
*ICML 2019* <span style="color:red">(Long Talk)</span> 
[[arXiv](https://arxiv.org/abs/1901.08779){:target="_blank"}] [[slides](https://bahh723.github.io/document/beating-stochastic-and-adversarial-semi-bandits-optimally-and-simultaneously.pdf){:target="_blank"}]


- **Bandit Multiclass Linear Classification: Efficient Algorithms for the Separable Case**  
(&alpha;-&beta;) Alina Beygelzimer, David Pal, Balazs Szorenyi, Devanathan Thiruvenkatachari, Chen-Yu Wei, Chicheng Zhang  
*ICML 2019* 
[[arXiv](https://arxiv.org/abs/1902.02244){:target="_blank"}] 
[[code](https://github.com/bahh723/separable-bandit-classification){:target="_blank"}] [[slides](https://bahh723.github.io/document/bandit-multiclass-linear-classification.pdf){:target="_blank"}]


### 2018

- **Efficient Online Portfolio with Logarithmic Regret**  
(&alpha;-&beta;) Haipeng Luo, Chen-Yu Wei, Kai Zheng  
*NeurIPS 2018* <span style="color:red">(Spotlight)</span> 
[[arXiv](https://arxiv.org/abs/1708.01799){:target="_blank"}] [[slides](https://bahh723.github.io/document/efficient-online-portfolio-with-logarithmic-regret.pdf){:target="_blank"}]

- **Efficient Contextual Bandits in Non-Stationary Worlds**  
Haipeng Luo\*, Chen-Yu Wei\*, Alekh Agarwal, John Langford  
*COLT 2018* 
[[arXiv](https://arxiv.org/abs/1708.01799){:target="_blank"}] [[slides](https://bahh723.github.io/document/efficient-contextual-bandits-in-non-stationary-worlds.pdf){:target="_blank"}] [[video](https://www.youtube.com/watch?v=VSJ-_ioGeZI){:target="_blank"}]


- **More Adaptive Algorithms for Adversarial Bandits**  
Chen-Yu Wei and Haipeng Luo  
*COLT 2018* 
[[arXiv](https://arxiv.org/abs/1801.03265){:target="_blank"}] [[slides](https://bahh723.github.io/document/more-adaptive-algorithms-for-adversarial-bandits.pdf){:target="_blank"}] [[video](https://www.youtube.com/watch?v=q5wGKMJ8tk0){:target="_blank"}]


- **Multi-Cell Cooperative Scheduling for Network Utility Maximization with User Equipment Side Interference Cancellation**  
Chen-Yu Wei and Wanjiun Liao  
*IEEE Transactions on Wireless Communications 2018* 
[[IEEE Xplore](https://ieeexplore.ieee.org/document/8100745){:target="_blank"}]


### Before 2018

- **Online Reinforcement Learning in Stochastic Games**  
Chen-Yu Wei, Yi-Te Hong, Chi-Jen Lu  
*NeurIPS 2017* 
[[arXiv](https://arxiv.org/abs/1712.00579){:target="_blank"}]

- **Tracking the Best Expert in Non-Stationary Stochastic Environments**  
Chen-Yu Wei, Yi-Te Hong, Chi-Jen Lu  
*NeurIPS 2016* 
[[arXiv](https://arxiv.org/abs/1712.00578){:target="_blank"}]

- **Adaptive Measurement for Energy Efficient Mobility Management in Ultra-Dense Small Cell Networks**  
Hsu Kao, Chen-Yu Wei, Hsiao-Ching Lin, Yi-Han Chiang, Wanjiun Liao  
*International Conference on Communications 2016* 
[[IEEE Xplore](https://ieeexplore.ieee.org/document/7511217){:target="_blank"}]

