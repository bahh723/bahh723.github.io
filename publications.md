---
title: "Publications"
permalink: "/publications/"
layout: page
--- 

The publication list can also be found on [Google Scholar](https://scholar.google.com/citations?user=2L2cR-kAAAAJ){:target="_blank"}.   
(&alpha;-&beta;) indicates alphabetical ordering; \* indicates equal contribution.  


## Publications 


### 2026   


- **Proximal Regret and Proximal Correlated Equilibria: A New Tractable Solution Concept for Online Learning and Games**   
(&alpha;-&beta;) Yang Cai, Constantinos Daskalakis, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng    
*STOC 2026* [[arXiv](https://arxiv.org/pdf/2511.01852){:target="_blank"}]  


- **An Improved Model-Free Decision-Estimation Coefficient with Applications in Adversarial MDPs**  
(&alpha;-&beta;) Haolin Liu, Chen-Yu Wei, Julian Zimmert    
*ICLR 2026* [[arXiv](https://arxiv.org/pdf/2510.08882){:target="_blank"}]



### 2025 



- **How Does Layer Normalization Improve Deep Q-Learning?**  
Braham Snyder, Hadi Daneshmand\*, Chen-Yu Wei\*     
*NeurIPS 2025 Workshop on Optimization for Machine Learning (OPT)* 
[[openreview](https://openreview.net/forum?id=r8bkE0TO1A){:target="_blank"}]  



- **An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction**   
(&alpha;-&beta;) Tim van Erven, Jack Mayo, Julia Olkhovskaya, Chen-Yu Wei  
*NeurIPS 2025* [[arXiv](https://arxiv.org/pdf/2508.11931){:target="_blank"}] [[slides](/document/adversarial-linear-contextual-bandits-via-reduction.pdf){:target="_blank"}] [[openreview](https://openreview.net/forum?id=MfhFiU28hv){:target="_blank"}]  


- **From Average-Iterate to Last-Iterate Convergence in Games: A Reduction and Its Applications**  
(&alpha;-&beta;) Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng   
*NeurIPS 2025* [[arXiv](https://arxiv.org/pdf/2506.03464){:target="_blank"}] [[openreview](https://openreview.net/forum?id=mG9xItYI0D){:target="_blank"}]  
  



- **HANQ: Hypergradients, Asymmetry, and Normalization for Fast and Stable Deep Q-Learning**  
Braham Snyder, Chen-Yu Wei  
*RLC 2025* 
[[openreview](https://openreview.net/forum?id=RkNGtcStxc){:target="_blank"}]  


- **Decision Making in Hybrid Environments: A Model Aggregation Approach**  
(&alpha;-&beta;) Haolin Liu, Chen-Yu Wei, Julian Zimmert    
*COLT 2025* 
[[arXiv](https://arxiv.org/pdf/2502.05974){:target="_blank"}] [[talk](https://youtu.be/uBIIuIX0pz0?si=AqKUaq1UZQy4i9Bx&t=3765){:target="_blank"}] 


### 2024 


- **Corruption-Robust Linear Bandits: Minimax Optimality and Gap-Dependent Misspecification**  
(&alpha;-&beta;) Haolin Liu, Artin Tajdini, Andrew Wagenmaker, Chen-Yu Wei  
*NeurIPS 2024* 
[[arXiv](https://arxiv.org/pdf/2410.07533){:target="_blank"}] [[openreview](https://openreview.net/forum?id=wqs2RMq4CW){:target="_blank"}] 



- **Beating Adversarial Low-Rank MDPs with Unknown Transition and Bandit Feedback**  
(&alpha;-&beta;) Haolin Liu, Zakaria Mhammedi, Chen-Yu Wei, Julian Zimmert  
*NeurIPS 2024* 
[[arXiv](https://arxiv.org/pdf/2411.06739){:target="_blank"}] [[openreview](https://openreview.net/forum?id=6ZXrvoIox1){:target="_blank"}] 

 

- **How Does Variance Shape the Regret in Contextual Bandits?**  
(&alpha;-&beta;) Zeyu Jia, Jian Qian, Alexander Rakhlin, Chen-Yu Wei   
*NeurIPS 2024* 
[[arXiv](https://arxiv.org/pdf/2410.12713){:target="_blank"}] [[openreview](https://openreview.net/forum?id=32Z3nfCnwa){:target="_blank"}]  


- **On Tractable &Phi;-Equilibria in Non-Concave Games**  
(&alpha;-&beta;) Yang Cai, Constantinos Daskalakis, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng   
*NeurIPS 2024*
[[arXiv](https://arxiv.org/pdf/2403.08171){:target="_blank"}] [[slides](https://docs.google.com/presentation/d/1PmAtSnLrAXfvc0AN2_0hupwA3kvCOPcU/edit?usp=sharing&ouid=112492238116028494469&rtpof=true&sd=true){:target="_blank"}] [[openreview](https://openreview.net/forum?id=3CtTMF5zzM){:target="_blank"}] [[openreview(rejected)](https://openreview.net/forum?id=li1Z0OQfnA){:target="_blank"}] 


- **Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data**  
(&alpha;-&beta;) Zeyu Jia, Alexander Rakhlin, Ayush Sekhari, Chen-Yu Wei   
*COLT 2024* 
[[arXiv](https://arxiv.org/pdf/2403.17091.pdf){:target="_blank"}] [[talk](https://www.youtube.com/watch?v=kQ9v0sy8Cao){:target="_blank"}] 
 


- **Near-Optimal Policy Optimization for Correlated Equilibrium in General-Sum Markov Games**  
(&alpha;-&beta;) Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng  
*AISTATS 2024* <span style="color:red">(Oral)</span> 
[[arXiv](https://arxiv.org/pdf/2401.15240){:target="_blank"}]  


- **Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback**  
(&alpha;-&beta;) Haolin Liu, Chen-Yu Wei, Julian Zimmert  
*ICLR 2024* <span style="color:red">(Spotlight)</span> 
[[arXiv](https://arxiv.org/pdf/2310.11550){:target="_blank"}] [[openreview](https://openreview.net/forum?id=6yv8UHVJn4){:target="_blank"}] 


### 2023


- **Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits**  
(&alpha;-&beta;) Haolin Liu, Chen-Yu Wei, Julian Zimmert  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/pdf/2309.00814){:target="_blank"}] [[talk](https://slideslive.com/39009540/bypassing-the-simulator-nearoptimal-adversarial-linear-contextual-bandits?ref=search-presentations){:target="_blank"}] [[openreview](https://openreview.net/forum?id=orh4e0AO9R){:target="_blank"}]


- **Last-Iterate Convergent Policy Gradient Primal-Dual Methods for Constrained MDPs**  
Dongsheng Ding\*, Chen-Yu Wei\*, Kaiqing Zhang\*, Alejandro Ribeiro  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/pdf/2306.11700){:target="_blank"}] [[talk](https://slideslive.com/39009306/lastiterate-convergent-policy-gradient-primaldual-methods-for-constrained-mdps?ref=search-presentations){:target="_blank"}] [[openreview](https://openreview.net/forum?id=U6bhCLSPun){:target="_blank"}]


- **No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions**  
Tiancheng Jin\*, Junyan Liu\*, Chloe Rouyer, William Chang, Chen-Yu Wei, Haipeng Luo  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/pdf/2305.17380){:target="_blank"}] [[talk](https://slideslive.com/39011477/noregret-online-reinforcement-learning-with-adversarial-losses-and-transitions?ref=search-presentations){:target="_blank"}] [[openreview](https://openreview.net/forum?id=0WLMVDdvDF){:target="_blank"}]


- **First- and Second-Order Bounds for Adversarial Linear Contextual Bandits**  
Julia Olkhovskaya, Jack Mayo, Tim van Erven, Gergely Neu, Chen-Yu Wei  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/pdf/2305.00832){:target="_blank"}] [[talk](https://slideslive.com/39009624/first-and-secondorder-bounds-for-adversarial-linear-contextual-bandits?ref=search-presentations){:target="_blank"}] [[openreview](https://openreview.net/forum?id=NTSbj2otOA){:target="_blank"}]


- **Uncoupled and Convergent Learning in Two-Player Zero-Sum Markov Games**  
(&alpha;-&beta;) Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng  
*NeurIPS 2023* 
[[arXiv](https://arxiv.org/pdf/2303.02738){:target="_blank"}] [[talk](https://slideslive.com/39009322/uncoupled-and-convergent-learning-in-twoplayer-zerosum-markov-games-with-bandit-feedback?ref=search-presentations){:target="_blank"}] [[openreview](https://openreview.net/forum?id=3xSwxlB0fd){:target="_blank"}]


- **A Blackbox Approach to Best of Both Worlds in Bandits and Beyond**  
(&alpha;-&beta;) Christoph Dann, Chen-Yu Wei, Julian Zimmert  
*COLT 2023* 
[[arXiv](https://arxiv.org/pdf/2302.09739){:target="_blank"}] [[slides](/document/blackbox-approach-to-best-of-both-worlds.pdf){:target="_blank"}]



- **Best of Both Worlds Policy Optimization**  
(&alpha;-&beta;) Christoph Dann, Chen-Yu Wei, Julian Zimmert  
*ICML 2023* <span style="color:red">(Long Talk)</span> 
[[arXiv](https://arxiv.org/pdf/2302.09408){:target="_blank"}] [[slides](/document/best-of-both-worlds-policy-optimization.pdf){:target="_blank"}] [[talk](https://slideslive.com/39006642/best-of-both-worlds-policy-optimization?ref=speaker-18927){:target="_blank"}]



- **Refined Regret for Adversarial MDPs with Linear Function Approximation**  
(&alpha;-&beta;) Yan Dai, Haipeng Luo, Chen-Yu Wei, Julian Zimmert  
*ICML 2023* 
[[arXiv](https://arxiv.org/pdf/2301.12942){:target="_blank"}] [[slides](https://diamond-duke.github.io/files/slides_ICML2023_Linear_AMDP.pdf){:target="_blank"}] [[talk](https://slideslive.com/39003236/refined-regret-for-adversarial-mdps-with-linear-function-approximation?ref=search-presentations){:target="_blank"}]



- **A Unified Algorithm for Stochastic Path Problems**  
(&alpha;-&beta;) Christoph Dann, Chen-Yu Wei, Julian Zimmert  
*ALT 2023* 
[[arXiv](https://arxiv.org/pdf/2210.09255){:target="_blank"}] [[slides](/document/unified-stochastic-path.pdf){:target="_blank"}]



### 2022

- **Independent Policy Gradient for Large-Scale Markov Potential Games: Sharper Rates, Function Approximation, and Game-Agnostic Convergence**  
Dongsheng Ding\*, Chen-Yu Wei\*, Kaiqing Zhang\*, Mihailo Jovanovic  
*ICML 2022* <span style="color:red">(Long Talk)</span> 
[[arXiv](https://arxiv.org/pdf/2202.04129){:target="_blank"}] [[talk](https://slideslive.com/38983099/independent-policy-gradient-for-largescale-markov-potential-games-sharper-rates-function-approximation-and-gameagnostic-convergence){:target="_blank"}]



- **Personalization Improves Privacy-Accuracy Tradeoffs in Federated Optimization**  
Alberto Bietti, Chen-Yu Wei, Miroslav Dudik, John Langford, Zhiwei Steven Wu  
*ICML 2022* 
[[arXiv](https://arxiv.org/pdf/2202.05318){:target="_blank"}] [[talk](https://slideslive.com/38983416/personalization-improves-privacyaccuracy-tradeoffs-in-federated-learning){:target="_blank"}]



- **Decentralized Cooperative Reinforcement Learning with Hierarchical Information Structure**  
Hsu Kao, Chen-Yu Wei, Vijay Subramanian  
*ALT 2022* 
[[arXiv](https://arxiv.org/pdf/2111.00781){:target="_blank"}] 
[[slides](/document/decentralized-cooperative-rl-in-hierarchical-mdp.pdf){:target="_blank"}]


- **A Model Selection Approach for Corruption Robust Reinforcement Learning**  
Chen-Yu Wei, Christoph Dann, Julian Zimmert  
*ALT 2022*  <span style="color:red">(Best Paper Award)</span> 
[[arXiv](https://arxiv.org/pdf/2110.03580){:target="_blank"}] [[slides](/document/model-selection-for-corrupted-mdp.pdf){:target="_blank"}]


### 2021

- **Policy Optimization in Adversarial MDPs:  Improved Exploration via Dilated Bonuses**  
Haipeng Luo\*, Chen-Yu Wei\*, Chung-Wei Lee  
*NeurIPS 2021* 
[[arXiv](https://arxiv.org/pdf/2107.08346){:target="_blank"}] 
[[slides](/document/policy-optimization-in-adversarial-mdp-with-dilated-bonus.pdf){:target="_blank"}]
[[slides](/document/exploration-bonus-for-policy-optimization.pdf){:target="_blank"}] [[talk](https://slideslive.com/38968587/policy-optimization-in-adversarial-mdps-improved-exploration-via-dilated-bonuses){:target="_blank"}] [[openreview](https://openreview.net/forum?id=XeM4Lld0zTR){:target="_blank"}]


- **Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic and Adversarial Linear Bandits Simultaneously**  
(&alpha;-&beta;) Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang, Xiaojin Zhang  
*ICML 2021* 
[[arXiv](https://arxiv.org/pdf/2102.05858){:target="_blank"}] [[slides](/document/best-of-both-worlds-for-linear-bandits.pdf){:target="_blank"}] [[talk](https://slideslive.com/38959312/achieving-near-instanceoptimality-and-minimaxoptimality-in-stochastic-and-adversarial-linear-bandits-simultaneously){:target="_blank"}]


- **Non-stationary Reinforcement Learning without Prior Knowledge: An Optimal Black-Box Approach**  
Chen-Yu Wei and Haipeng Luo  
*COLT 2021*  <span style="color:red">(Best Paper Award)</span> 
[[arXiv](https://arxiv.org/pdf/2102.05406){:target="_blank"}] [[slides](/document/non-stationary-rl.pdf){:target="_blank"}] [[slides](/document/non-stationary-bandit.pdf){:target="_blank"}] [[talk](https://www.youtube.com/watch?v=kLMVbPnD5kc){:target="_blank"}]


- **Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent in Infinite-Horizon Competitive Markov Games**  
Chen-Yu Wei, Chung-Wei Lee\*, Mengxiao Zhang\*, Haipeng Luo  
*COLT 2021* 
[[arXiv](https://arxiv.org/pdf/2102.04540){:target="_blank"}] [[slides](/document/last-iterate-convergence-of-ogda-in-markov-games.pdf){:target="_blank"}]

- **Impossible Tuning Made Possible: A New Expert Algorithm and Its Applications**  
(&alpha;-&beta;) Liyu Chen, Haipeng Luo, Chen-Yu Wei  
*COLT 2021* 
[[arXiv](https://arxiv.org/pdf/2102.01046){:target="_blank"}] [[slides](/document/impossible-tuning-made-possible.pdf){:target="_blank"}]

- **Minimax Regret for Stochastic Shortest Path with Adversarial Costs and Known Transition**  
Liyu Chen, Haipeng Luo, Chen-Yu Wei  
*COLT 2021* 
[[arXiv](https://arxiv.org/pdf/2012.04053){:target="_blank"}] [[slides](/document/adversarial-stochastic-shortest-path-with-known-transition.pdf){:target="_blank"}] [[talk](https://www.youtube.com/watch?v=uneHM2mm3z0){:target="_blank"}]


- **Learning Infinite-Horizon Average-Reward MDPs with Linear Function Approximation**  
Chen-Yu Wei, Mehdi Jafarnia-Jahromi, Haipeng Luo, Rahul Jain  
*AISTATS 2021* 
[[arXiv](https://arxiv.org/pdf/2007.11849){:target="_blank"}] [[slides](/document/average-reward-linear-mdp.pdf){:target="_blank"}] [[talk](https://www.youtube.com/watch?v=NpG97aEctqE){:target="_blank"}]


- **Linear Last-Iterate Convergence in Constrained Saddle-Point Optimization**  
Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, Haipeng Luo  
*ICLR 2021* 
[[arXiv](https://arxiv.org/pdf/2006.09517){:target="_blank"}] [[code](https://github.com/bahh723/OGDA-last-iterate){:target="_blank"}] 
[[slides](/document/linear-last-iterate-convergence-in-constrained-saddle-point-optimization.pdf){:target="_blank"}] [[talk](https://slideslive.com/38954127/linear-lastiterate-convergence-in-constrained-saddlepoint-optimization){:target="_blank"}] [[review](https://openreview.net/forum?id=dx11_7vm5_r){:target="_blank"}]


- **Adversarial Online Learning with Changing Action Sets: Efficient Algorithms with Approximate Regret Bounds**  
Ehsan Emamjomeh-Zadeh\*, Chen-Yu Wei\*, Haipeng Luo, David Kempe  
*ALT 2021* 
[[arXiv](https://arxiv.org/pdf/2003.03490){:target="_blank"}] [[slides](/document/adversarial-online-learning-with-changing-action-sets.pdf){:target="_blank"}] [[talk](https://slideslive.com/38952813/adversarial-online-learning-with-changing-action-sets-efficient-algorithms-with-approximate-regret-bounds){:target="_blank"}]


### 2020

- **Bias No More: High-Probability Data-Dependent Regret Bounds for Adversarial Bandits and MDPs**  
(&alpha;-&beta;) Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang  
*NeurIPS 2020*  <span style="color:red">(Oral)</span> 
[[arXiv](https://arxiv.org/pdf/2006.08040){:target="_blank"}] [[slides](/document/bias-no-more.pdf){:target="_blank"}] [[talk](https://slideslive.com/38938490/bias-no-more-highprobability-datadependent-regret-bounds-for-adversarial-bandits-and-mdps){:target="_blank"}]

- **Federated Residual Learning**  
Chen-Yu Wei, Alekh Agarwal, John Langford  
*NeurIPS Workshop on Scalability, Privacy, and Security in Federated Learning 2020* 
[[arXiv](https://arxiv.org/pdf/2003.12880){:target="_blank"}] 


- **Taking a Hint: How to Leverage Loss Predictors in Contextual Bandits?**  
Chen-Yu Wei, Haipeng Luo, Alekh Agarwal  
*COLT 2020* 
[[arXiv](https://arxiv.org/pdf/2003.01922){:target="_blank"}] [[slides](/document/how-to-leverage-loss-predictors-in-contextual-bandits.pdf){:target="_blank"}] [[talk](https://slideslive.com/38931095/taking-a-hint-how-to-leverage-loss-predictors-in-contextual-bandits){:target="_blank"}]


- **Model-free Reinforcement Learning in Infinite-Horizon Average-Reward Markov Decision Processes**  
Chen-Yu Wei, Mehdi Jafarnia-Jahromi, Haipeng Luo, Hiteshi Sharma, Rahul Jain  
*ICML 2020* 
[[arXiv](https://arxiv.org/pdf/1910.07072){:target="_blank"}] 
[[code](https://github.com/bahh723/model-free-rl-algos){:target="_blank"}] [[slides](/document/model-free-rl-in-infinite-horizon-average-reward-mdp.pdf){:target="_blank"}] [[talk](https://slideslive.com/38928250/modelfree-reinforcement-learning-in-infinitehorizon-averagereward-mdps){:target="_blank"}]



### 2019

- **Analyzing the Variance of Policy Gradient Estimators for the Linear-Quadratic Regulator**  
James Preiss\*, Sebastien Arnold\*, Chen-Yu Wei\*, Marius Kloft  
*NeurIPS Workshop on Optimization Foundations for Reinforcement Learning 2019* [[arXiv](https://arxiv.org/pdf/1910.01249){:target="_blank"}]  
*SoCal Machine Learning Symposium 2019* <span style="color:red">(Best Poster Award)</span> 

- **A New Algorithm for Non-Stationary Contextual Bandits: Efficient, Optimal, and Parameter-Free**  
(&alpha;-&beta;) Yifang Chen, Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei  
*COLT 2019* 
[[arXiv](https://arxiv.org/pdf/1902.00980){:target="_blank"}] 
[[joint extended abstract with Auer, Gajane, and Ortner](http://proceedings.mlr.press/v99/auer19b.html){:target="_blank"}] [[slides](/document/a-new-algorithm-for-non-stationary-contextual-bandits.pdf){:target="_blank"}]

- **Improved Path-Length Regret Bounds for Bandits**  
(&alpha;-&beta;) Sebastien Bubeck, Yuanzhi Li, Haipeng Luo, Chen-Yu Wei  
*COLT 2019* 
[[arXiv](https://arxiv.org/pdf/1901.10604){:target="_blank"}] [[slides](/document/improved-path-length-regret-bounds-for-bandits.pdf){:target="_blank"}]


- **Beating Stochastic and Adversarial Semi-Bandits Optimally and Simultaneously**  
Julian Zimmert, Haipeng Luo, Chen-Yu Wei  
*ICML 2019* <span style="color:red">(Long Talk)</span> 
[[arXiv](https://arxiv.org/pdf/1901.08779){:target="_blank"}] [[slides](/document/beating-stochastic-and-adversarial-semi-bandits-optimally-and-simultaneously.pdf){:target="_blank"}]


- **Bandit Multiclass Linear Classification: Efficient Algorithms for the Separable Case**  
(&alpha;-&beta;) Alina Beygelzimer, David Pal, Balazs Szorenyi, Devanathan Thiruvenkatachari, Chen-Yu Wei, Chicheng Zhang  
*ICML 2019* 
[[arXiv](https://arxiv.org/pdf/1902.02244){:target="_blank"}] 
[[code](https://github.com/bahh723/separable-bandit-classification){:target="_blank"}] [[slides](/document/bandit-multiclass-linear-classification.pdf){:target="_blank"}]


### 2018

- **Efficient Online Portfolio with Logarithmic Regret**  
(&alpha;-&beta;) Haipeng Luo, Chen-Yu Wei, Kai Zheng  
*NeurIPS 2018* <span style="color:red">(Spotlight)</span> 
[[arXiv](https://arxiv.org/abs/1805.07430){:target="_blank"}] [[slides](/document/efficient-online-portfolio-with-logarithmic-regret.pdf){:target="_blank"}]

- **Efficient Contextual Bandits in Non-Stationary Worlds**  
Haipeng Luo\*, Chen-Yu Wei\*, Alekh Agarwal, John Langford  
*COLT 2018* 
[[arXiv](https://arxiv.org/pdf/1708.01799){:target="_blank"}] [[slides](/document/efficient-contextual-bandits-in-non-stationary-worlds.pdf){:target="_blank"}] [[talk](https://www.youtube.com/watch?v=VSJ-_ioGeZI){:target="_blank"}]


- **More Adaptive Algorithms for Adversarial Bandits**  
Chen-Yu Wei and Haipeng Luo  
*COLT 2018* 
[[arXiv](https://arxiv.org/pdf/1801.03265){:target="_blank"}] [[slides](/document/more-adaptive-algorithms-for-adversarial-bandits.pdf){:target="_blank"}] [[talk](https://www.youtube.com/watch?v=q5wGKMJ8tk0){:target="_blank"}]


- **Multi-Cell Cooperative Scheduling for Network Utility Maximization with User Equipment Side Interference Cancellation**  
Chen-Yu Wei and Wanjiun Liao  
*IEEE Transactions on Wireless Communications 2018* 
[[IEEE Xplore](https://ieeexplore.ieee.org/document/8100745){:target="_blank"}]


### Before 2018

- **Online Reinforcement Learning in Stochastic Games**  
Chen-Yu Wei, Yi-Te Hong, Chi-Jen Lu  
*NeurIPS 2017* 
[[arXiv](https://arxiv.org/pdf/1712.00579){:target="_blank"}]

- **Tracking the Best Expert in Non-Stationary Stochastic Environments**  
Chen-Yu Wei, Yi-Te Hong, Chi-Jen Lu  
*NeurIPS 2016* 
[[arXiv](https://arxiv.org/pdf/1712.00578){:target="_blank"}]

- **Adaptive Measurement for Energy Efficient Mobility Management in Ultra-Dense Small Cell Networks**  
Hsu Kao, Chen-Yu Wei, Hsiao-Ching Lin, Yi-Han Chiang, Wanjiun Liao  
*International Conference on Communications 2016* 
[[IEEE Xplore](https://ieeexplore.ieee.org/document/7511217){:target="_blank"}]


## Other Presentations         

- **Swap Regret and Strategic Learning**  
Theory seminar talk at UVA, 2025       
[[slides](/document/swap-regret.pdf){:target="_blank"}]  


- **Collusion in Algorithmic Pricing**  
Guest lecture in UVA CS6501: *Economics of Distributed Systems*, 2024   
Invited talk at UMD CS Seminar, 2024     
[[slides](/document/algorithmic-pricing.pdf){:target="_blank"}]  

- **Some Recent Advances in Bandit Theory**  
Colloquium talk at NTUEE, 2022   
[[slides](/document/bandits.pdf){:target="_blank"}]    
